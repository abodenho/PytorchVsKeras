{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Les imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D  # traite les image ( vu qu'il sont en 2d)\n",
    "from tensorflow.keras.layers import MaxPooling2D  # pour la récupération d'information importante\n",
    "from tensorflow.keras.layers import Flatten  # feature map pour les applatir\n",
    "from tensorflow.keras.layers import Dense  # ajout de couche\n",
    "from tensorflow.keras.layers import Dropout  # probabilité pour \"endormir\" les neurone\n",
    "from tensorflow.keras.models import Sequential  # initialise le réseau de neuronne\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "from commun.informationLearningWriter import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Paramètres Généraux"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "dir = \"CNN\"  # le directory des photos\n",
    "\n",
    "path2write = \"./\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Paramètress du modèle de l'IA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "nbrHiddenLayer = 3\n",
    "neuroneCoucheCacher = 128\n",
    "tailleLot = 32\n",
    "nbrPoolConv = 4\n",
    "fctActivation = 'relu'\n",
    "optimizer = 'adam'\n",
    "imageSize = 150\n",
    "rateDropOut = 0.3\n",
    "shearRange = 0.2\n",
    "zoomRange = 0.2\n",
    "activationConvolution = 'relu'\n",
    "nbEpoque = 15\n",
    "nbFiltre = 32\n",
    "kernelSize = 3\n",
    "stridesConv = 1\n",
    "stridesPool = 2\n",
    "allMetrics = [\"acc\"]\n",
    "sizeMatricePool = (2, 2)\n",
    "folderTrain = dir + \"/\" + \"training_set\"\n",
    "folderTest = dir + \"/\" + \"test_set\"\n",
    "\n",
    "outUnit = 1\n",
    "fctLoss = \"binary_crossentropy\"\n",
    "classMode = 'binary'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comptage du nombre d'images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def comptageTot(folderPathTrain, folderPathTest):\n",
    "    \"\"\" compte le nombre total de photo \"\"\"\n",
    "    imageTest = 0\n",
    "    imageTrain = 0\n",
    "    foldersTest = os.listdir(folderPathTest)\n",
    "    foldersTrain = os.listdir(folderPathTrain)\n",
    "    for subFolders in foldersTrain:\n",
    "        imageTrain += comptageImage(folderPathTrain + \"/\" + subFolders)\n",
    "    for subFolders in foldersTest:\n",
    "        imageTest += comptageImage(folderPathTest + \"/\" + subFolders)\n",
    "    return (imageTrain, imageTest)\n",
    "\n",
    "\n",
    "def comptageImage(pathFolder):\n",
    "    folder = os.listdir(pathFolder)\n",
    "    return len(folder)\n",
    "\n",
    "\n",
    "nbImageTrain, nbImageTest = comptageTot(folderTrain, folderTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construction de l'IA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    # phase traitement image\n",
    "    model.add(Convolution2D(filters=nbFiltre, kernel_size=kernelSize, strides=stridesConv, input_shape=(imageSize, imageSize, 3),\n",
    "                            activation=activationConvolution))\n",
    "    # Phase de convolution , on transforme l'image avec la fonction de convolution grace a des filtre pour avoir un set de featurs map\n",
    "    model.add(MaxPooling2D(pool_size=sizeMatricePool, strides=stridesPool))\n",
    "    # Phase de Pooling ( avec le max pooling ) , permet de réduire la taille en gardant l'information la plus importante ( pour les différente prise de vue)\n",
    "\n",
    "    nbrLayer = 1\n",
    "    multiplicateur = 1\n",
    "    for i in range(nbrPoolConv - 1):\n",
    "        model.add(Convolution2D(filters=nbFiltre * multiplicateur, kernel_size=kernelSize, strides=stridesConv,\n",
    "                                activation=activationConvolution))\n",
    "        model.add(MaxPooling2D(pool_size=sizeMatricePool, strides=stridesPool))\n",
    "        nbrLayer += 1\n",
    "        multiplicateur = math.floor((nbrLayer / 2) + 1)\n",
    "\n",
    "    # phase feed forward\n",
    "    model.add(Flatten())  # Couche d'entrée\n",
    "    # Etape de flattening ( linéarise la matrice de pooling feature map pour le réseau de ANN)\n",
    "\n",
    "    for j in range(nbrHiddenLayer):\n",
    "        model.add(Dense(units=neuroneCoucheCacher, activation=fctActivation))\n",
    "\n",
    "    ##Couche de sortie\n",
    "    model.add(Dropout(rateDropOut))\n",
    "    model.add(Dense(units=outUnit, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=fctLoss, metrics=allMetrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "CNN = buildModel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generateur d'image (sert au rescaling)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train = train_datagen.flow_from_directory(folderTrain,\n",
    "                                          target_size=(imageSize,imageSize),\n",
    "                                          batch_size= )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN/training_set\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrainement de l'IA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-28903d943941>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m saves = CNN.fit(\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mfolderTrain\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mceil\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnbImageTrain\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mtailleLot\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnbEpoque\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfolderTest\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 108\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1047\u001B[0m          \u001B[0mtraining_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mRespectCompiledTrainableState\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1048\u001B[0m       \u001B[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1049\u001B[1;33m       data_handler = data_adapter.DataHandler(\n\u001B[0m\u001B[0;32m   1050\u001B[0m           \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1051\u001B[0m           \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001B[0m\n\u001B[0;32m   1103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m     \u001B[0madapter_cls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mselect_data_adapter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1105\u001B[1;33m     self._adapter = adapter_cls(\n\u001B[0m\u001B[0;32m   1106\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1107\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    648\u001B[0m         sample_weights, sample_weight_modes)\n\u001B[0;32m    649\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 650\u001B[1;33m     self._internal_adapter = TensorLikeDataAdapter(\n\u001B[0m\u001B[0;32m    651\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    652\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    273\u001B[0m     \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack_x_y_sample_weight\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 275\u001B[1;33m     \u001B[0mnum_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    276\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    277\u001B[0m       \u001B[0mmsg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Data cardinality is ambiguous:\\n\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    273\u001B[0m     \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpack_x_y_sample_weight\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 275\u001B[1;33m     \u001B[0mnum_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    276\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_samples\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    277\u001B[0m       \u001B[0mmsg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"Data cardinality is ambiguous:\\n\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\PytorchVsKeras\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    885\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    886\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_v2_behavior\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 887\u001B[1;33m           \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dims\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    889\u001B[0m           \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dims\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "saves = CNN.fit(\n",
    "    folderTrain,\n",
    "    steps_per_epoch=math.ceil(nbImageTrain / tailleLot),\n",
    "    epochs=nbEpoque,\n",
    "    validation_data=folderTest,\n",
    "    validation_steps=math.ceil(nbImageTest / tailleLot),\n",
    "    verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sauvegarde des Information lier a l'apprentissage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writeIntoFile(saves.history['val_acc'],saves.history['acc'],path2write)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}