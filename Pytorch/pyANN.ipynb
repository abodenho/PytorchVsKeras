{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "from commun.CONSTANTE import *\n",
    "import torch\n",
    "from commun.CommunFonction import writeIntoFilesKeras\n",
    "from commun.datasets.dataManager import DataManager\n",
    "import torch.optim as optim\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "beginTime = time.time()\n",
    "data = DataManager(\"../commun/datasets/ANN/Churn_Modelling_traited.csv\")\n",
    "\n",
    "\n",
    "trainTensor,trainLabelTensor = data.getTrainCSV()\n",
    "testTensor, testLabelTensor = data.getTestCSV()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Traitement data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "trainTensor,trainLabelTensor = torch.tensor(trainTensor).float(),torch.tensor(trainLabelTensor).unsqueeze(1).float()\n",
    "testTensor, testLabelTensor  = torch.tensor(testTensor).float(),torch.tensor(testLabelTensor).unsqueeze(1).float()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def splitBatch(tensorToSplit,numberBatch):\n",
    "    lstBatch = []\n",
    "    sizeBatch = len(tensorToSplit)/numberBatch\n",
    "    for i in range(numberBatch):\n",
    "        supBorne = ceil(sizeBatch*(i+1))\n",
    "        infBorne = ceil(sizeBatch*i)\n",
    "        lstBatch.append(tensorToSplit[infBorne:supBorne][:])\n",
    "\n",
    "    return lstBatch\n",
    "\n",
    "trainBatch = splitBatch(trainTensor, BATCH_SIZE)\n",
    "trainBatchLabel = splitBatch(trainLabelTensor,BATCH_SIZE)\n",
    "testBatch = splitBatch(testTensor,BATCH_SIZE)\n",
    "testBatchLabel = splitBatch(testLabelTensor,BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Création modèle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(ANN_NUMBER_INPUT,NUMBER_NEURONE_HIDDEN_LAYER_ANN),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(NUMBER_NEURONE_HIDDEN_LAYER_ANN,NUMBER_NEURONE_HIDDEN_LAYER_ANN),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(NUMBER_NEURONE_HIDDEN_LAYER_ANN,NUMBER_NEURONE_HIDDEN_LAYER_ANN),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(NUMBER_NEURONE_HIDDEN_LAYER_ANN,NUMBER_NEURONE_OUTPUT),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def calculateAccuracy(result,target):\n",
    "    goodPredictionTensor = (result > 0.5) == target\n",
    "    total = len(goodPredictionTensor)\n",
    "    goodPrediction = 0\n",
    "    for boolean in goodPredictionTensor:\n",
    "        if boolean:\n",
    "            goodPrediction +=1\n",
    "    return goodPrediction/total\n",
    "\n",
    "def calculateMean(lstValue):\n",
    "    total = 0\n",
    "    for valueAcc in lstValue:\n",
    "        total += valueAcc\n",
    "    return total/len(lstValue)\n",
    "\n",
    "lstAcc = []\n",
    "lstValAcc = []\n",
    "lstLoss = []\n",
    "lstValLoss = []\n",
    "\n",
    "def trainLoop(numberEpoch,optimizer,model,lossFunction,\n",
    "              trainBatch,trainBatchLabel,\n",
    "              testBatch,testBatchLabel):\n",
    "\n",
    "    for epoch in range(1,numberEpoch+1):\n",
    "        subLstAcc = []\n",
    "        subLstAccVal = []\n",
    "        subLstLoss = []\n",
    "        subLstLossVal = []\n",
    "        for train,trainLabel,test,testLabel in zip(trainBatch,trainBatchLabel,\n",
    "                                                   testBatch,testBatchLabel):\n",
    "            resultTrain = model(train)\n",
    "            subLstAcc.append(calculateAccuracy(resultTrain,trainLabel))\n",
    "            lossTrain = lossFunction(resultTrain,trainLabel)\n",
    "            subLstLoss.append(lossTrain.item())\n",
    "            with torch.no_grad(): #désactive l'accumulation pour mise a jour des poids et biais\n",
    "                resultTest = model(test)\n",
    "                subLstAccVal.append(calculateAccuracy(resultTest,testLabel))\n",
    "                lossTest = lossFunction(resultTest,testLabel)\n",
    "                subLstLossVal.append(lossTest.item())\n",
    "\n",
    "            optimizer.zero_grad() #met a jour le buffer servant a l'accumulation\n",
    "            # pour la mise a jour poids et biais(époque précédente)\n",
    "            lossTrain.backward() #calcule le gradient des donnée\n",
    "            optimizer.step() #met a jours les données \n",
    "\n",
    "        lstAcc.append(calculateMean(subLstAcc))\n",
    "        lstValAcc.append(calculateMean(subLstAccVal))\n",
    "        lstLoss.append(calculateMean(subLstLoss))\n",
    "        lstValLoss.append(calculateMean(subLstLossVal))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40225, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.7973750000000001, 0.798375, 0.8023750000000001, 0.8066250000000003, 0.8117500000000002]\n",
      "[0.3976494495647723, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.7919306835637483, 0.79242671530978, 0.7969230030721968, 0.8004192268305174, 0.8024433563748081]\n",
      "[0.7030991334468126, 0.6186714544892311, 0.518258847296238, 0.499027656391263, 0.491517161950469, 0.48356879968196154, 0.47475664503872395, 0.46960633248090744, 0.4659541817381978, 0.46260677743703127, 0.4591627214103937, 0.45532796531915665, 0.4510288508608937, 0.44637748412787914, 0.4417111035436392]\n",
      "[0.7039840072393417, 0.6223315894603729, 0.5258154543116689, 0.5057820100337267, 0.49935947451740503, 0.49221518728882074, 0.4848182871937752, 0.4789510425180197, 0.473908425308764, 0.4692811956629157, 0.4647797867655754, 0.459947532042861, 0.4546563969925046, 0.449069251306355, 0.4434788776561618]\n"
     ]
    }
   ],
   "source": [
    "trainLoop(NUMBER_EPOCH,optimizer,model,nn.BCELoss(),\n",
    "          trainBatch,trainBatchLabel,\n",
    "          testBatch, testBatchLabel)\n",
    "endTime = time.time() - beginTime\n",
    "\n",
    "print(lstAcc)\n",
    "print(lstValAcc)\n",
    "print(lstLoss)\n",
    "print(lstValLoss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "writeIntoFilesKeras(lstAcc,lstValAcc,lstLoss,lstValLoss,endTime,\"pytorch_ANN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}